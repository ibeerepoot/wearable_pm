{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0400b65",
   "metadata": {},
   "source": [
    "# Enrich events\n",
    "Make sure to fill in the device_name (your Apple Watch device name) and that the following files are present:\n",
    "- calendar.csv (an exported csv file from Outlook)\n",
    "- export.xml (the exported XML file from Apple Health)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea9f794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "device_name = \"Enter your wearable name here\"\n",
    "\n",
    "tree = ET.parse('export.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "hrv_data = []\n",
    "\n",
    "for record in root.findall('Record'):\n",
    "        \n",
    "    if record.attrib.get('type') == 'HKQuantityTypeIdentifierHeartRateVariabilitySDNN':\n",
    "        hrv_data.append({\n",
    "            'start': record.attrib['startDate'],\n",
    "            'end': record.attrib['endDate'],\n",
    "            'value_ms': float(record.attrib['value']),\n",
    "            'source': record.attrib.get('sourceName', 'unknown')\n",
    "        })\n",
    "\n",
    "hrv_df = pd.DataFrame(hrv_data)\n",
    "hrv_df['start'] = pd.to_datetime(hrv_df['start'])\n",
    "hrv_df['date'] = hrv_df['start'].dt.date\n",
    "\n",
    "# store the first and last date for later use\n",
    "first_date = hrv_df['date'].min()\n",
    "last_date = hrv_df['date'].max()\n",
    "\n",
    "# Bekijk de eerste rijen\n",
    "hrv_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd99323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('calendar.csv')\n",
    "\n",
    "columns_to_drop = [\n",
    "    'Reminder on/off', 'Reminder Date', 'Reminder Time', 'Meeting Resources',\n",
    "    'Billing Information', 'Categories', 'Mileage', 'Priority', 'Private',\n",
    "    'Sensitivity', 'Show time as'\n",
    "]\n",
    "\n",
    "df = df.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# Merge Start Date and Start Time, End Date and End Time\n",
    "df['Start'] = pd.to_datetime(df['Start Date'] + ' ' + df['Start Time'])\n",
    "df['End'] = pd.to_datetime(df['End Date'] + ' ' + df['End Time'])\n",
    "\n",
    "df = df.drop(columns=['Start Date', 'Start Time', 'End Date', 'End Time'], errors='ignore')\n",
    "\n",
    "# Drop rows where 'All day event' is 'True'\n",
    "df = df[df['All day event'] != True]\n",
    "\n",
    "# Filter df to only keep rows between first_date and last_date\n",
    "df = df[(df['Start'].dt.date >= first_date) & (df['End'].dt.date <= last_date)]\n",
    "\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ad50f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Start'] = df['Start'].dt.tz_localize('Europe/Amsterdam')  # Of jouw tijdzone\n",
    "df['End'] = df['End'].dt.tz_localize('Europe/Amsterdam')\n",
    "\n",
    "hrv_df['start'] = pd.to_datetime(hrv_df['start'])\n",
    "hrv_df['end'] = pd.to_datetime(hrv_df['end'])\n",
    "\n",
    "def get_hrv_stats(row):\n",
    "    overlap = hrv_df[\n",
    "        (hrv_df['end'] >= row['Start']) &\n",
    "        (hrv_df['start'] <= row['End'])\n",
    "    ]['value_ms']\n",
    "\n",
    "    if len(overlap) == 0:\n",
    "        return pd.Series({'HRV_mean': None, 'HRV_median': None})\n",
    "    else:\n",
    "        return pd.Series({\n",
    "            'HRV_mean': overlap.mean(),\n",
    "            'HRV_median': overlap.median()\n",
    "        })\n",
    "\n",
    "df[['HRV_mean', 'HRV_median']] = df.apply(get_hrv_stats, axis=1)\n",
    "\n",
    "df_with_hrv = df[df['HRV_mean'].notna() | df['HRV_median'].notna()]\n",
    "\n",
    "# Save unique Subject values to labelling.csv, for manual anonymization\n",
    "pd.DataFrame({'Subject': df_with_hrv['Subject'].unique()}).to_csv('labelling.csv', index=False)\n",
    "\n",
    "df_with_hrv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3230e292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Normalize Subject names for IPO events: case-insensitive grouping\n",
    "ipo_df = df_with_hrv[df_with_hrv[\"Subject\"].str.lower().str.startswith(\"ipo\", na=False)].copy()\n",
    "ipo_df[\"NormalizedSubject\"] = ipo_df[\"Subject\"].str.lower().str.strip().str.title()\n",
    "\n",
    "# Define custom mappings for specific subjects\n",
    "#custom_map = {\n",
    "#    \"ipo [online]\": \"Ipo David\",\n",
    "#    \"ipo?\": \"Ipo David\",\n",
    "#    \"ipo huckepuckebahnhof\": \"Ipo Julia\",\n",
    "#    \"ipo zoo - inga annemarie lieneke\": \"Ipo Julia\"\n",
    "#}\n",
    "\n",
    "# Apply custom mapping (case-insensitive)\n",
    "#ipo_df[\"NormalizedSubject\"] = ipo_df[\"NormalizedSubject\"].replace(custom_map)\n",
    "\n",
    "# Capitalize remaining categories nicely\n",
    "ipo_df[\"NormalizedSubject\"] = ipo_df[\"NormalizedSubject\"].str.title()\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "\n",
    "# Group by initials (first letter after \"Ipo\")\n",
    "ipo_df[\"Initial\"] = ipo_df[\"NormalizedSubject\"].apply(\n",
    "    lambda x: x.split()[1][0] if len(x.split()) > 1 else x[0]\n",
    ")\n",
    "\n",
    "# Ensure groups are sorted by Start before plotting lines\n",
    "for initial, group in ipo_df.groupby(\"Initial\"):\n",
    "    group_sorted = group.sort_values(\"Start\")\n",
    "    plt.plot(group_sorted[\"Start\"], group_sorted[\"HRV_median\"],\n",
    "             linestyle=\"--\", marker=None, alpha=0.4, color=\"gray\")\n",
    "    for i, row in group_sorted.iterrows():\n",
    "        plt.text(row[\"Start\"], row[\"HRV_median\"], initial, fontsize=12, fontweight=\"bold\",\n",
    "                 ha=\"center\", va=\"center\", color=\"black\")\n",
    "\n",
    "# Set axis limits properly\n",
    "plt.xlim(ipo_df[\"Start\"].min() - pd.Timedelta(days=1), ipo_df[\"Start\"].max() + pd.Timedelta(days=1))\n",
    "plt.ylim(ipo_df[\"HRV_median\"].min() - 5, ipo_df[\"HRV_median\"].max() + 5)\n",
    "\n",
    "plt.title(\"HRV Values Across Single Meeting Type\", fontsize=14, fontweight=\"bold\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Median HRV (ms)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd69229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Subject for robust matching (lowercase, strip spaces)\n",
    "df_with_hrv[\"NormalizedSubject\"] = df_with_hrv[\"Subject\"].str.lower().str.strip()\n",
    "\n",
    "# Define meeting patterns to match (lowercase for comparison)\n",
    "meeting_subjects = [\"mt\", \"office update (via teams)\", \"update front office\"]\n",
    "\n",
    "# Filter rows where Subject matches one of the meeting types (case-insensitive)\n",
    "recurring_df = df_with_hrv[df_with_hrv[\"NormalizedSubject\"].isin(meeting_subjects)].copy()\n",
    "\n",
    "# Create short labels\n",
    "label_map = {\n",
    "    \"mt\": \"M\",\n",
    "    \"office update (via teams)\": \"O\",\n",
    "    \"update front office\": \"F\"\n",
    "}\n",
    "recurring_df[\"Label\"] = recurring_df[\"NormalizedSubject\"].map(label_map)\n",
    "\n",
    "# Only proceed if we found matches\n",
    "if not recurring_df.empty:\n",
    "    plt.figure(figsize=(6,6))\n",
    "\n",
    "    # Plot chronological connections\n",
    "    for label, group in recurring_df.groupby(\"Label\"):\n",
    "        group_sorted = group.sort_values(\"Start\")\n",
    "        plt.plot(group_sorted[\"Start\"], group_sorted[\"HRV_median\"],\n",
    "                 linestyle=\"--\", marker=None, alpha=0.4, color=\"gray\")\n",
    "        for i, row in group_sorted.iterrows():\n",
    "            plt.text(row[\"Start\"], row[\"HRV_median\"], row[\"Label\"],\n",
    "                     fontsize=12, fontweight=\"bold\", ha=\"center\", va=\"center\")\n",
    "\n",
    "    # Set axis limits properly\n",
    "    plt.xlim(recurring_df[\"Start\"].min() - pd.Timedelta(days=1), recurring_df[\"Start\"].max() + pd.Timedelta(days=1))\n",
    "    plt.ylim(recurring_df[\"HRV_median\"].min() - 5, recurring_df[\"HRV_median\"].max() + 5)\n",
    "\n",
    "    plt.title(\"HRV Values Across Recurrent Meetings\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Median HRV (ms)\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No matching recurrent meetings found. Please check Subject names.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a27b3a",
   "metadata": {},
   "source": [
    "# Enrich cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f509e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "resting_hr_data = []\n",
    "\n",
    "for record in root.findall('Record'):\n",
    "    if (record.attrib.get('type') == 'HKQuantityTypeIdentifierRestingHeartRate' and\n",
    "        record.attrib.get('sourceName') == device_name):\n",
    "        \n",
    "        resting_hr_data.append({\n",
    "            'start': pd.to_datetime(record.attrib['startDate']),\n",
    "            'value_bpm': float(record.attrib['value']),\n",
    "            'source': record.attrib.get('sourceName', 'unknown')\n",
    "        })\n",
    "\n",
    "# Zet in DataFrame\n",
    "restingHR_df = pd.DataFrame(resting_hr_data)\n",
    "\n",
    "# Voeg datumkolom toe\n",
    "restingHR_df['date'] = restingHR_df['start'].dt.date\n",
    "\n",
    "# Bereken gemiddelde rusthartslag per dag (je kunt ook .min() of .first() doen)\n",
    "restingHR_df = restingHR_df.groupby('date', as_index=False)['value_bpm'].mean()\n",
    "\n",
    "# Optioneel: hernoem kolommen voor consistentie\n",
    "restingHR_df = restingHR_df.rename(columns={'value_bpm': 'resting_hr_bpm'})\n",
    "\n",
    "# Sort descending by resting_hr_bpm\n",
    "restingHR_df = restingHR_df.sort_values('resting_hr_bpm', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Bekijk het resultaat\n",
    "restingHR_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea17106",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_data = []\n",
    "\n",
    "for record in root.findall('Record'):\n",
    "    if (record.attrib.get('type') == 'HKCategoryTypeIdentifierSleepAnalysis' and\n",
    "        record.attrib.get('sourceName') == device_name):\n",
    "        sleep_data.append({\n",
    "            'type': 'sleep',\n",
    "            'start': record.attrib['startDate'],\n",
    "            'end': record.attrib['endDate'],\n",
    "            'value': record.attrib['value'],\n",
    "            'source': record.attrib.get('sourceName', 'unknown')\n",
    "        })\n",
    "\n",
    "if sleep_data:\n",
    "    sleep_df = pd.DataFrame(sleep_data)\n",
    "    sleep_df['start'] = pd.to_datetime(sleep_df['start'])\n",
    "    sleep_df['end'] = pd.to_datetime(sleep_df['end'])\n",
    "    display(sleep_df)\n",
    "else:\n",
    "    print(\"No sleep records found for device.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e017170c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sleep_data = []\n",
    "\n",
    "for record in root.findall('Record'):\n",
    "    if (record.attrib.get('type') == 'HKCategoryTypeIdentifierSleepAnalysis' and\n",
    "        record.attrib.get('sourceName') == device_name):\n",
    "        sleep_data.append({\n",
    "            'type': 'sleep',\n",
    "            'start': record.attrib['startDate'],\n",
    "            'end': record.attrib['endDate'],\n",
    "            'value': record.attrib['value'],\n",
    "            'source': record.attrib.get('sourceName', 'unknown')\n",
    "        })\n",
    "\n",
    "if sleep_data:\n",
    "    sleep_df = pd.DataFrame(sleep_data)\n",
    "    sleep_df['start'] = pd.to_datetime(sleep_df['start'])\n",
    "    sleep_df['end'] = pd.to_datetime(sleep_df['end'])\n",
    "\n",
    "    # Compute duration in minutes\n",
    "    sleep_df['duration_min'] = (sleep_df['end'] - sleep_df['start']).dt.total_seconds() / 60\n",
    "\n",
    "    # Assign each record to the \"night of\" its start date\n",
    "    # If someone goes to bed after midnight, shift back to the previous date\n",
    "    sleep_df['night'] = sleep_df['start'].dt.date\n",
    "    sleep_df.loc[sleep_df['start'].dt.hour < 12, 'night'] = sleep_df.loc[sleep_df['start'].dt.hour < 12, 'night'] - pd.to_timedelta(1, unit='d')\n",
    "\n",
    "    # Aggregate per night and sleep stage (value)\n",
    "    sleep_agg = sleep_df.groupby(['night', 'value'])['duration_min'].sum().reset_index()\n",
    "\n",
    "    # Pivot to have sleep stages as columns\n",
    "    sleep_pivot = sleep_agg.pivot(index='night', columns='value', values='duration_min').fillna(0)\n",
    "\n",
    "else:\n",
    "    print(\"No sleep records found for device.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57bfff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83dca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure datetime\n",
    "df['Start'] = pd.to_datetime(df['Start'])\n",
    "df['End'] = pd.to_datetime(df['End'])\n",
    "\n",
    "# Keep only events that start and end on the same calendar date\n",
    "df = df[df['Start'].dt.date == df['End'].dt.date].copy()\n",
    "\n",
    "# 1. Build daily event sequences from df\n",
    "df['workday'] = df['Start'].dt.date\n",
    "day_sequences = (\n",
    "    df.sort_values('Start')\n",
    "      .groupby('workday')['Subject']\n",
    "      .apply(list)\n",
    "      .reset_index()\n",
    "      .rename(columns={'Subject': 'event_sequence'})\n",
    ")\n",
    "\n",
    "# 2. Reset index for sleep_pivot and ensure 'night' is date\n",
    "sleep_pivot = sleep_pivot.reset_index()\n",
    "sleep_pivot['night'] = pd.to_datetime(sleep_pivot['night']).dt.date\n",
    "\n",
    "# 3. Shift sleep nights back by one day so each workday is linked to the following night\n",
    "sleep_pivot['workday'] = sleep_pivot['night'] - pd.to_timedelta(1, unit='d')\n",
    "\n",
    "# Add a TotalSleep column: sum Core, Deep, and REM\n",
    "sleep_pivot['TotalSleep'] = (\n",
    "    sleep_pivot.get('HKCategoryValueSleepAnalysisAsleepCore', 0) +\n",
    "    sleep_pivot.get('HKCategoryValueSleepAnalysisAsleepDeep', 0) +\n",
    "    sleep_pivot.get('HKCategoryValueSleepAnalysisAsleepREM', 0)\n",
    ")\n",
    "\n",
    "\n",
    "# 4. Merge workday sequences with the *following* night's sleep\n",
    "merged = pd.merge(\n",
    "    day_sequences,\n",
    "    sleep_pivot,\n",
    "    on='workday',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Drop duplicate 'night' column if desired\n",
    "merged = merged.drop(columns=['night'])\n",
    "\n",
    "merged\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb032cbe",
   "metadata": {},
   "source": [
    "# Enrich activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe2efdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "workout_data = []\n",
    "\n",
    "for workout in root.findall('Workout'):\n",
    "    if workout.attrib.get('sourceName') == device_name:\n",
    "        # sla op\n",
    "        workout_data.append({\n",
    "            'type': 'workout',\n",
    "            'start': workout.attrib['startDate'],\n",
    "            'end': workout.attrib['endDate'],\n",
    "            'activity': workout.attrib.get('workoutActivityType'),\n",
    "            'duration_min': float(workout.attrib.get('duration', 0)),\n",
    "            'source': workout.attrib.get('sourceName', 'unknown')\n",
    "        })\n",
    "\n",
    "workout_df = pd.DataFrame(workout_data)\n",
    "workout_df['start'] = pd.to_datetime(workout_df['start'])\n",
    "workout_df['end'] = pd.to_datetime(workout_df['end'])\n",
    "\n",
    "workout_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f61c14",
   "metadata": {},
   "source": [
    "# Build event log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02811ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labelling.csv\n",
    "label_df = pd.read_csv('labelled.csv', sep=';')\n",
    "\n",
    "# Create mapping from Subject to Label\n",
    "subject_to_label = dict(zip(label_df['Subject'], label_df['Label']))\n",
    "\n",
    "# Replace Subject with Label in df_with_hrv\n",
    "df_with_hrv['Subject'] = df_with_hrv['Subject'].map(subject_to_label)\n",
    "\n",
    "# Copy df_with_hrv and drop specified columns\n",
    "event_log = df_with_hrv.drop(\n",
    "    columns=[\n",
    "        'NormalizedSubject',\n",
    "        'All day event',\n",
    "        'Meeting Organizer',\n",
    "        'Required Attendees',\n",
    "        'Optional Attendees',\n",
    "        'Description',\n",
    "        'Location',\n",
    "        'HRV_mean'\n",
    "    ],\n",
    "    errors='ignore'\n",
    ")\n",
    "\n",
    "# Rename NormalizedSubject to Activity in event_log\n",
    "event_log = event_log.rename(columns={'Subject': 'Activity'})\n",
    "\n",
    "# Prepare workout_df for appending\n",
    "workout_events = workout_df[['start', 'end', 'activity']].copy()\n",
    "workout_events = workout_events.rename(columns={\n",
    "    'start': 'Start',\n",
    "    'end': 'End',\n",
    "    'activity': 'Activity',\n",
    "})\n",
    "\n",
    "# Add missing columns to workout_events to match event_log structure\n",
    "for col in event_log.columns:\n",
    "    if col not in workout_events.columns:\n",
    "        workout_events[col] = None\n",
    "workout_events = workout_events[event_log.columns]  # Ensure column order\n",
    "\n",
    "# Append workout_events to event_log\n",
    "event_log = pd.concat([event_log, workout_events], ignore_index=True)\n",
    "\n",
    "# Clean up Activity values: remove 'HKWorkoutActivityType' prefix\n",
    "event_log['Activity'] = event_log['Activity'].replace(\n",
    "    r'^HKWorkoutActivityType', '', regex=True\n",
    ").str.strip()\n",
    "\n",
    "event_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8743e8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tz(dt):\n",
    "    try:\n",
    "        dt = pd.to_datetime(dt)\n",
    "        if pd.isnull(dt):\n",
    "            return pd.NaT\n",
    "        if hasattr(dt, 'tzinfo') and dt.tzinfo is not None:\n",
    "            return dt.tz_localize(None)\n",
    "        return dt\n",
    "    except Exception:\n",
    "        return pd.NaT\n",
    "\n",
    "event_log['Start'] = event_log['Start'].apply(remove_tz)\n",
    "event_log['End'] = event_log['End'].apply(remove_tz)\n",
    "event_log['Workday'] = event_log['Start'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Filter out Workdays that contain only Activities starting with 'Private' or 'Sports'\n",
    "def is_only_private_or_sports(activities):\n",
    "    return all(a.startswith('Private') or a.startswith('Sports') for a in activities)\n",
    "\n",
    "def has_work_activity(activities):\n",
    "    return any(a.startswith('Work') for a in activities)\n",
    "\n",
    "# Group by Workday and filter\n",
    "filtered_days = (\n",
    "    event_log.groupby('Workday')['Activity']\n",
    "    .apply(list)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Keep only Workdays with at least one 'Work' activity\n",
    "valid_workdays = filtered_days[filtered_days['Activity'].apply(has_work_activity)]['Workday']\n",
    "\n",
    "# Filter event_log\n",
    "event_log = event_log[event_log['Workday'].isin(valid_workdays)]\n",
    "\n",
    "# Prepare sleep_df for appending to event_log\n",
    "sleep_events = sleep_df[['start', 'end', 'value', 'night']].copy()\n",
    "sleep_events = sleep_events.rename(columns={\n",
    "    'start': 'Start',\n",
    "    'end': 'End',\n",
    "    'value': 'Activity',\n",
    "    'night': 'Workday'\n",
    "})\n",
    "\n",
    "# Add missing columns to sleep_events to match event_log structure\n",
    "for col in event_log.columns:\n",
    "    if col not in sleep_events.columns:\n",
    "        sleep_events[col] = None\n",
    "sleep_events = sleep_events[event_log.columns]  # Ensure column order\n",
    "\n",
    "# Append sleep_events to event_log\n",
    "event_log = pd.concat([event_log, sleep_events], ignore_index=True)\n",
    "\n",
    "event_log['Start'] = event_log['Start'].apply(remove_tz)\n",
    "event_log['End'] = event_log['End'].apply(remove_tz)\n",
    "\n",
    "event_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63507be",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_log['RestingHR'] = None\n",
    "\n",
    "# Create a mapping from date to resting_hr_bpm\n",
    "resting_hr_map = dict(zip(restingHR_df['date'].astype(str), restingHR_df['resting_hr_bpm']))\n",
    "\n",
    "# Assign RestingHR to event_log based on Workday\n",
    "event_log['RestingHR'] = event_log['Workday'].map(resting_hr_map)\n",
    "\n",
    "event_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a90ad51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mappings from merged for each sleep variable\n",
    "total_sleep_map = dict(zip(merged['workday'].astype(str), merged['TotalSleep']))\n",
    "awake_map = dict(zip(merged['workday'].astype(str), merged.get('HKCategoryValueSleepAnalysisAwake', pd.Series())))\n",
    "deep_sleep_map = dict(zip(merged['workday'].astype(str), merged.get('HKCategoryValueSleepAnalysisAsleepDeep', pd.Series())))\n",
    "\n",
    "# Assign to event_log based on Workday\n",
    "event_log['TotalSleep'] = event_log['Workday'].map(total_sleep_map)\n",
    "event_log['Awake'] = event_log['Workday'].map(awake_map)\n",
    "event_log['DeepSleep'] = event_log['Workday'].map(deep_sleep_map)\n",
    "\n",
    "# Clean up Activity values: remove 'HKCategoryValueSleepAnalysisAsleepCore' prefix\n",
    "event_log['Activity'] = event_log['Activity'].replace(\n",
    "    r'^HKCategoryValueSleepAnalysis', '', regex=True\n",
    ").str.strip()\n",
    "\n",
    "event_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43b83e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_log.to_csv('event_log.csv', index=False)\n",
    "\n",
    "event_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f2fcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude sleep-related activities from event_log\n",
    "exclude_activities = ['AsleepREM', 'Awake', 'AsleepCore', 'AsleepDeep', 'AsleepUnspecified']\n",
    "\n",
    "filtered_event_log = event_log[~event_log['Activity'].isin(exclude_activities)]\n",
    "\n",
    "filtered_event_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e52bc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select the workdays of interest\n",
    "selected_days = ['2024-11-20', '2025-05-22', '2024-12-11', '2024-12-31', '2025-06-13']\n",
    "selected_df = event_log[event_log['Workday'].isin(selected_days)]\n",
    "\n",
    "# Aggregate by Workday (in case there are multiple activities per day)\n",
    "agg = selected_df.groupby('Workday')[['RestingHR', 'TotalSleep', 'Awake', 'DeepSleep']].first().reset_index()\n",
    "\n",
    "# Calculate overall averages for reference\n",
    "overall_means = event_log[['RestingHR', 'TotalSleep', 'Awake', 'DeepSleep']].mean()\n",
    "\n",
    "# Plot: metrics underneath each other (vertical subplots)\n",
    "fig, axes = plt.subplots(4, 1, figsize=(2, 6), sharex=True)\n",
    "metrics = ['RestingHR', 'TotalSleep', 'Awake', 'DeepSleep']\n",
    "\n",
    "for ax, metric in zip(axes, metrics):\n",
    "    ax.bar(agg['Workday'], agg[metric], label='Selected days')\n",
    "    ax.axhline(overall_means[metric], color='red', linestyle='--', label='Overall mean')\n",
    "    #ax.set_title(metric)\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.grid(True, linestyle='--', alpha=0.5)\n",
    "    #ax.legend()\n",
    "\n",
    "axes[-1].set_xticklabels(agg['Workday'], rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184c4e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only include activities that occur at least twice\n",
    "activity_counts = filtered_event_log['Activity'].value_counts()\n",
    "valid_activities = activity_counts[activity_counts >= 2].index\n",
    "\n",
    "filtered_event_log_twice = filtered_event_log[filtered_event_log['Activity'].isin(valid_activities)]\n",
    "\n",
    "# Calculate average and median RestingHR, TotalSleep, Awake, and DeepSleep for each unique Activity\n",
    "summary = (\n",
    "    filtered_event_log_twice\n",
    "    .groupby('Activity')[['RestingHR', 'TotalSleep', 'Awake', 'DeepSleep']]\n",
    "    .agg(['mean', 'median'])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "summary.to_csv('activity_summary.csv', index=False)\n",
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
